{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f712724e",
   "metadata": {},
   "source": [
    "# DuAT Model Training for Medical Image Segmentation\n",
    "\n",
    "This notebook trains the DuAT model on your custom dataset with the following structure:\n",
    "- train/images (.jpg)\n",
    "- train/masks (.png with 0-255 values)\n",
    "- val/images (.jpg)\n",
    "- val/masks (.png with 0-255 values)\n",
    "- test/images (.jpg, no masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from lib.DuAT import DuAT\n",
    "from utils.utils import clip_gradient, AvgMeter\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fab385",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "Set your dataset paths here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths - Update these paths according to your data location\n",
    "TRAIN_IMAGES_PATH = \"path/to/your/train/images\"\n",
    "TRAIN_MASKS_PATH = \"path/to/your/train/masks\"\n",
    "VAL_IMAGES_PATH = \"path/to/your/val/images\"\n",
    "VAL_MASKS_PATH = \"path/to/your/val/masks\"\n",
    "TEST_IMAGES_PATH = \"path/to/your/test/images\"\n",
    "OUTPUT_PATH = \"predictions\"\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = 352\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "CLIP_GRADIENT = 0.5\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(\"model_checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e37356",
   "metadata": {},
   "source": [
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, image_size=352, is_training=True):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.image_size = image_size\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.image_files.sort()\n",
    "        \n",
    "        # Define transforms\n",
    "        if is_training:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST),\n",
    "                A.HorizontalFlip(p=0.3),\n",
    "                A.VerticalFlip(p=0.3),\n",
    "                A.RandomBrightnessContrast(p=0.2),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load mask\n",
    "        mask_name = img_name.replace('.jpg', '.png').replace('.jpeg', '.png')\n",
    "        mask_path = os.path.join(self.masks_path, mask_name)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask.astype(np.float32) / 255.0  # Normalize to 0-1\n",
    "        \n",
    "        # Apply transforms\n",
    "        transformed = self.transform(image=image, mask=mask)\n",
    "        \n",
    "        return transformed['image'], transformed['mask'].unsqueeze(0)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images_path, image_size=352):\n",
    "        self.images_path = images_path\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.image_files.sort()\n",
    "        \n",
    "        # Define transforms\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Store original size for later use\n",
    "        original_size = image.shape[:2]\n",
    "        \n",
    "        # Apply transforms\n",
    "        transformed = self.transform(image=image)\n",
    "        \n",
    "        return transformed['image'], img_name, original_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795595a",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d519d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_loss(pred, mask):\n",
    "    \"\"\"\n",
    "    Structure loss function combining weighted BCE and weighted IoU\n",
    "    \"\"\"\n",
    "    weit = 1 + 5 * torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n",
    "    wbce = F.binary_cross_entropy_with_logits(pred, mask, reduction='none')\n",
    "    wbce = (weit * wbce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    inter = ((pred * mask) * weit).sum(dim=(2, 3))\n",
    "    union = ((pred + mask) * weit).sum(dim=(2, 3))\n",
    "    wiou = 1 - (inter + 1) / (union - inter + 1)\n",
    "\n",
    "    return (wbce + wiou).mean()\n",
    "\n",
    "def dice_coefficient(pred, target, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculate Dice coefficient\n",
    "    \"\"\"\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01b7d7",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Validate the model and return average dice score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_dice = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output1, output2 = model(images)\n",
    "            \n",
    "            # Combine outputs\n",
    "            combined_output = output1 + output2\n",
    "            \n",
    "            # Calculate dice coefficient\n",
    "            dice = dice_coefficient(combined_output, masks)\n",
    "            total_dice += dice.item() * images.size(0)\n",
    "            total_samples += images.size(0)\n",
    "    \n",
    "    avg_dice = total_dice / total_samples\n",
    "    return avg_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112cff1",
   "metadata": {},
   "source": [
    "## Model Initialization and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = DuAT().to(device)\n",
    "print(\"Model initialized successfully!\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomSegmentationDataset(\n",
    "    TRAIN_IMAGES_PATH, TRAIN_MASKS_PATH, \n",
    "    image_size=IMAGE_SIZE, is_training=True\n",
    ")\n",
    "\n",
    "val_dataset = CustomSegmentationDataset(\n",
    "    VAL_IMAGES_PATH, VAL_MASKS_PATH, \n",
    "    image_size=IMAGE_SIZE, is_training=False\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, \n",
    "    shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, \n",
    "    shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36ea59",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "val_dice_scores = []\n",
    "best_dice = 0.0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    # Training metrics\n",
    "    loss_meter = AvgMeter()\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output1, output2 = model(images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss1 = structure_loss(output1, masks)\n",
    "        loss2 = structure_loss(output2, masks)\n",
    "        total_loss = loss1 + loss2\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        clip_gradient(optimizer, CLIP_GRADIENT)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        loss_meter.update(total_loss.item(), images.size(0))\n",
    "        \n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss_meter.avg:.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    val_dice = validate_model(model, val_loader, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save metrics\n",
    "    train_losses.append(loss_meter.avg)\n",
    "    val_dice_scores.append(val_dice)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] - Train Loss: {loss_meter.avg:.4f}, Val Dice: {val_dice:.4f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), 'model_checkpoints/best_model.pth')\n",
    "        print(f'New best model saved! Dice: {best_dice:.4f}')\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'model_checkpoints/checkpoint_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation Dice score: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a3490",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abac406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_dice_scores)\n",
    "plt.title('Validation Dice Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7775420f",
   "metadata": {},
   "source": [
    "## Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178176e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model, test_loader, output_path, device):\n",
    "    \"\"\"\n",
    "    Predict on test data and save results\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Starting prediction on test data...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, filenames, original_sizes) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output1, output2 = model(images)\n",
    "            \n",
    "            # Combine outputs and apply sigmoid\n",
    "            combined_output = torch.sigmoid(output1 + output2)\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            for i in range(images.size(0)):\n",
    "                pred_mask = combined_output[i, 0].cpu().numpy()\n",
    "                filename = filenames[i]\n",
    "                original_h, original_w = original_sizes[0][i].item(), original_sizes[1][i].item()\n",
    "                \n",
    "                # Resize prediction to original size\n",
    "                pred_mask_resized = cv2.resize(pred_mask, (original_w, original_h), interpolation=cv2.INTER_CUBIC)\n",
    "                \n",
    "                # Convert to 0-255 range\n",
    "                pred_mask_uint8 = (pred_mask_resized * 255).astype(np.uint8)\n",
    "                \n",
    "                # Save prediction\n",
    "                output_filename = filename.replace('.jpg', '.png').replace('.jpeg', '.png')\n",
    "                output_filepath = os.path.join(output_path, output_filename)\n",
    "                cv2.imwrite(output_filepath, pred_mask_uint8)\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f'Processed {batch_idx + 1}/{len(test_loader)} batches')\n",
    "    \n",
    "    print(f\"Predictions saved to: {output_path}\")\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('model_checkpoints/best_model.pth'))\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = TestDataset(TEST_IMAGES_PATH, image_size=IMAGE_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Run prediction\n",
    "predict_test_data(model, test_loader, OUTPUT_PATH, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b387b9",
   "metadata": {},
   "source": [
    "## Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, val_loader, device, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualize some predictions on validation data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    sample_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output1, output2 = model(images)\n",
    "            predictions = torch.sigmoid(output1 + output2)\n",
    "            \n",
    "            for i in range(min(images.size(0), num_samples - sample_count)):\n",
    "                # Convert tensors to numpy\n",
    "                image = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                # Denormalize image\n",
    "                image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                image = np.clip(image, 0, 1)\n",
    "                \n",
    "                mask = masks[i, 0].cpu().numpy()\n",
    "                pred = predictions[i, 0].cpu().numpy()\n",
    "                \n",
    "                # Plot\n",
    "                axes[sample_count, 0].imshow(image)\n",
    "                axes[sample_count, 0].set_title('Original Image')\n",
    "                axes[sample_count, 0].axis('off')\n",
    "                \n",
    "                axes[sample_count, 1].imshow(mask, cmap='gray')\n",
    "                axes[sample_count, 1].set_title('Ground Truth')\n",
    "                axes[sample_count, 1].axis('off')\n",
    "                \n",
    "                axes[sample_count, 2].imshow(pred, cmap='gray')\n",
    "                axes[sample_count, 2].set_title('Prediction')\n",
    "                axes[sample_count, 2].axis('off')\n",
    "                \n",
    "                sample_count += 1\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions(model, val_loader, device, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23260eae",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Model training is complete! Here's what was accomplished:\n",
    "\n",
    "1. **Data Loading**: Custom dataset classes for your specific data structure\n",
    "2. **Training**: Full training loop with validation monitoring\n",
    "3. **Model Saving**: Best model saved based on validation Dice score\n",
    "4. **Testing**: Predictions generated for test data and saved to output folder\n",
    "5. **Visualization**: Training history plots and sample predictions\n",
    "\n",
    "### Files Generated:\n",
    "- `model_checkpoints/best_model.pth`: Best performing model\n",
    "- `model_checkpoints/checkpoint_epoch_*.pth`: Regular checkpoints\n",
    "- `predictions/`: Folder containing test predictions\n",
    "- `training_history.png`: Training loss and validation metrics\n",
    "- `sample_predictions.png`: Visual comparison of predictions\n",
    "\n",
    "### Next Steps:\n",
    "- Evaluate predictions using your preferred metrics\n",
    "- Fine-tune hyperparameters if needed\n",
    "- Apply post-processing to predictions if required"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
